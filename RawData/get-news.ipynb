{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dùng get-news để crawl dữ liệu tin tức\n",
    "\n",
    "## 1. Import thư viện để crawl\n",
    "Dùng thư viện news-please, thư viện này từ repo sau [fhamborg/news-please](https://github.com/fhamborg/news-please). Nhược điểm của thư viện này - chưa crawl được url của hình ảnh hoặc video trong các bài báo đã crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from newsplease import NewsPlease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Các dữ liệu tin tức giả\n",
    "URL về Fake News, tập hợp từ các bài viết có nội dung không được xác minh về nguồn tin, hoặc được xác nhận sai,... Có thể lưu url các bài báo trong 1 file text (mỗi url là 1 dòng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_urls = [''\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bắt đầu crawl dữ liệu tin tức giả đưa vào list fake_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_articles = []\n",
    "for fake_url in fake_news_urls:\n",
    "    fake_articles.append(NewsPlease.from_url(fake_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tên của các file json sẽ chứa nội dung vừa crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_no = 9\n",
    "fake_prefix = 'VFND_Ac_Fake_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đưa các dữ liệu vừa crawl vào các file json dữ liệu. Các thông số cho json.dump lần lượt là: __default = str__ đưa tất cả về string để tránh lỗi trong quá trình parse dữ liệu dạng _datetime_ sang json của các trường date\\_modify, date\\_download, date\\_publish; __ensure\\_ascii=False__ là để giữ các dữ liệu text ở dạng Unicode - để không bị lỗi khi đưa vào file json khi để text ở định dạng Unicode, thì trong phần __open()__ đặt thông số _encoding='utf-8'_. \n",
    "\n",
    "Các biến:\n",
    "1. fake\\_name: tên file để lưu\n",
    "2. fake\\_no: số thứ tự của file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Fake/VFND_Ac_Fake_9.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8ca78f02ecd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mfake_no\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfake_no\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Fake/VFND_Ac_Fake_9.json'"
     ]
    }
   ],
   "source": [
    "for fake in fake_articles:\n",
    "    fake_name = fake_prefix + str(fake_no) + '.json' \n",
    "    fake_no = fake_no + 1\n",
    "    \n",
    "    with open(fake_name, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(fake.__dict__, outfile, indent=4, sort_keys=True, default=str, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test các kết quả trả ra khi crawl ở cell dưới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (fake_articles[0].__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Các dữ liệu tin tức thật"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_news_urls = ['https://news.zing.vn/bo-cong-thuong-ket-luan-con-cung-co-sai-sot-nhung-khong-ban-hang-gia-post869549.html',\n",
    "                  ''\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bắt đầu crawl dữ liệu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_articles = []\n",
    "for real_url in real_news_urls:\n",
    "    real_articles.append(NewsPlease.from_url(real_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_no = 7\n",
    "real_prefix = './Real/VFND_Ac_Real_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tương tự với việc crawl dữ liệu về tin tức giả. Ta có danh sách 1 số biến:\n",
    "1. real\\_name: tên file để lưu\n",
    "2. real\\_no: số thứ tự của file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in real_articles:\n",
    "    real_name = real_prefix + str(real_no) + '.json'\n",
    "    real_no = real_no + 1\n",
    "    with open(real_name, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(real.__dict__, outfile, indent=4, sort_keys=True, default=str, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test các kết quả trả ra khi crawl ở cell dưới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(real_articles[0].__dict__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
